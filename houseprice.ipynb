{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gJr_9dXGpJ05",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9Eqt_Q5HQD3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ff7661b2-2a69-4f8b-92ac-f0057475ac6d"
      },
      "source": [
        "train = pd.read_csv(\"/train.csv\")\n",
        "test = pd.read_csv(\"/test.csv\")\n",
        "#train.isnull().sum()\n",
        "train.info()     \n",
        "comb = pd.concat([train, test], axis=0, sort=False)\n",
        "\n",
        "#comb.info()\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1460 entries, 0 to 1459\n",
            "Data columns (total 81 columns):\n",
            "Id               1460 non-null int64\n",
            "MSSubClass       1460 non-null int64\n",
            "MSZoning         1460 non-null object\n",
            "LotFrontage      1201 non-null float64\n",
            "LotArea          1460 non-null int64\n",
            "Street           1460 non-null object\n",
            "Alley            91 non-null object\n",
            "LotShape         1460 non-null object\n",
            "LandContour      1460 non-null object\n",
            "Utilities        1460 non-null object\n",
            "LotConfig        1460 non-null object\n",
            "LandSlope        1460 non-null object\n",
            "Neighborhood     1460 non-null object\n",
            "Condition1       1460 non-null object\n",
            "Condition2       1460 non-null object\n",
            "BldgType         1460 non-null object\n",
            "HouseStyle       1460 non-null object\n",
            "OverallQual      1460 non-null int64\n",
            "OverallCond      1460 non-null int64\n",
            "YearBuilt        1460 non-null int64\n",
            "YearRemodAdd     1460 non-null int64\n",
            "RoofStyle        1460 non-null object\n",
            "RoofMatl         1460 non-null object\n",
            "Exterior1st      1460 non-null object\n",
            "Exterior2nd      1460 non-null object\n",
            "MasVnrType       1452 non-null object\n",
            "MasVnrArea       1452 non-null float64\n",
            "ExterQual        1460 non-null object\n",
            "ExterCond        1460 non-null object\n",
            "Foundation       1460 non-null object\n",
            "BsmtQual         1423 non-null object\n",
            "BsmtCond         1423 non-null object\n",
            "BsmtExposure     1422 non-null object\n",
            "BsmtFinType1     1423 non-null object\n",
            "BsmtFinSF1       1460 non-null int64\n",
            "BsmtFinType2     1422 non-null object\n",
            "BsmtFinSF2       1460 non-null int64\n",
            "BsmtUnfSF        1460 non-null int64\n",
            "TotalBsmtSF      1460 non-null int64\n",
            "Heating          1460 non-null object\n",
            "HeatingQC        1460 non-null object\n",
            "CentralAir       1460 non-null object\n",
            "Electrical       1459 non-null object\n",
            "1stFlrSF         1460 non-null int64\n",
            "2ndFlrSF         1460 non-null int64\n",
            "LowQualFinSF     1460 non-null int64\n",
            "GrLivArea        1460 non-null int64\n",
            "BsmtFullBath     1460 non-null int64\n",
            "BsmtHalfBath     1460 non-null int64\n",
            "FullBath         1460 non-null int64\n",
            "HalfBath         1460 non-null int64\n",
            "BedroomAbvGr     1460 non-null int64\n",
            "KitchenAbvGr     1460 non-null int64\n",
            "KitchenQual      1460 non-null object\n",
            "TotRmsAbvGrd     1460 non-null int64\n",
            "Functional       1460 non-null object\n",
            "Fireplaces       1460 non-null int64\n",
            "FireplaceQu      770 non-null object\n",
            "GarageType       1379 non-null object\n",
            "GarageYrBlt      1379 non-null float64\n",
            "GarageFinish     1379 non-null object\n",
            "GarageCars       1460 non-null int64\n",
            "GarageArea       1460 non-null int64\n",
            "GarageQual       1379 non-null object\n",
            "GarageCond       1379 non-null object\n",
            "PavedDrive       1460 non-null object\n",
            "WoodDeckSF       1460 non-null int64\n",
            "OpenPorchSF      1460 non-null int64\n",
            "EnclosedPorch    1460 non-null int64\n",
            "3SsnPorch        1460 non-null int64\n",
            "ScreenPorch      1460 non-null int64\n",
            "PoolArea         1460 non-null int64\n",
            "PoolQC           7 non-null object\n",
            "Fence            281 non-null object\n",
            "MiscFeature      54 non-null object\n",
            "MiscVal          1460 non-null int64\n",
            "MoSold           1460 non-null int64\n",
            "YrSold           1460 non-null int64\n",
            "SaleType         1460 non-null object\n",
            "SaleCondition    1460 non-null object\n",
            "SalePrice        1460 non-null int64\n",
            "dtypes: float64(3), int64(35), object(43)\n",
            "memory usage: 924.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzQ7PfeWHTyM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e480132b-e42b-442d-9dee-8f150922bced"
      },
      "source": [
        "train['Street'].value_counts()\n",
        "print(comb[comb['PoolQC'].notnull()]['PoolQC'])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "197     Ex\n",
            "810     Fa\n",
            "1170    Gd\n",
            "1182    Ex\n",
            "1298    Gd\n",
            "1386    Fa\n",
            "1423    Gd\n",
            "514     Ex\n",
            "1113    Ex\n",
            "1250    Gd\n",
            "Name: PoolQC, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHp6smcyHbtc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "1b46d835-450b-49de-be40-92be5d5f8041"
      },
      "source": [
        "#update the duplicate values \n",
        "numeric_var_list = ['LotFrontage','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','BsmtFullBath','BsmtHalfBath','GarageYrBlt','GarageCars','GarageArea']\n",
        "categorical_val_list = ['MSZoning','Alley','Utilities','Exterior1st','Exterior2nd','MasVnrType','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','Electrical','KitchenQual','SaleType','Functional','FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PoolQC','Fence','MiscFeature']\n",
        "\n",
        "#update the missed numaric values by mean\n",
        "\n",
        "#comb['LotFrontage'] = comb['LotFrontage'].fillna(comb['LotFrontage'].mean())\n",
        "\n",
        "for nv in numeric_var_list:\n",
        "  comb[nv] = comb[nv].fillna(comb[nv]).median()\n",
        "for cv in categorical_val_list:\n",
        "  comb[cv] = comb[cv].fillna(comb[cv]).mode()[0]\n",
        "  \n",
        "\n",
        "for c,type in zip(comb.columns,comb.dtypes):\n",
        "  if(type=='object'):\n",
        "    temp1=pd.get_dummies(comb[c],drop_first=True)\n",
        "    comb = pd.concat([comb,temp1],axis=1)\n",
        "    comb.drop([c],axis=1,inplace=True) \n",
        "\n",
        "#Remove the duplicate columns    \n",
        "comb = comb.loc[:,~comb.columns.duplicated()]    \n",
        "  \n",
        "  \n",
        "#comb.isnull().sum()  \n",
        "#comb.info()\n",
        "\n",
        "#1460\n",
        "\n",
        "#df_Train=final_df.iloc[:1422,:]\n",
        "#df_Test=final_df.iloc[1422:,:]\n",
        "train_x = comb.iloc[:1460,:]\n",
        "test_x =  comb.iloc[1460:,:]\n",
        "train_y = train_x[train_x['SalePrice'].notnull()]['SalePrice']\n",
        "\n",
        "train_x.drop(['SalePrice'],axis=1,inplace=True)\n",
        "test_x.drop(['SalePrice'],axis=1,inplace=True)\n",
        "\n",
        "print(train_x.shape)\n",
        "print(test_x.shape)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1460, 126)\n",
            "(1459, 126)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  errors=errors)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBLWZTGIHfQ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "cb35bef1-2666-43cf-eba5-b0d7a0865274"
      },
      "source": [
        "#SPlit the categorized values and concat with the initial values\n",
        "#lab_dtype = train_x.dtypes\n",
        "#train_x.dtypes\n",
        "#train_x.dtypes\n",
        "\n",
        "'''\n",
        "for c,type in zip(train_x.columns,train_x.dtypes):\n",
        "  if(type=='object'):\n",
        "    temp1=pd.get_dummies(train_x[c],drop_first=True)\n",
        "    train_x = pd.concat([train_x,temp1],axis=1)\n",
        "    train_x.drop([c],axis=1,inplace=True)\n",
        "\n",
        "    \n",
        "for c,type in zip(test_x.columns,test_x.dtypes):\n",
        "    temp1=pd.get_dummies(test_x[c],drop_first=True)\n",
        "    test_x = pd.concat([test_x,temp1],axis=1)\n",
        "    test_x.drop([c],axis=1,inplace=True)\n",
        "    \n",
        "'''"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfor c,type in zip(train_x.columns,train_x.dtypes):\\n  if(type=='object'):\\n    temp1=pd.get_dummies(train_x[c],drop_first=True)\\n    train_x = pd.concat([train_x,temp1],axis=1)\\n    train_x.drop([c],axis=1,inplace=True)\\n\\n    \\nfor c,type in zip(test_x.columns,test_x.dtypes):\\n    temp1=pd.get_dummies(test_x[c],drop_first=True)\\n    test_x = pd.concat([test_x,temp1],axis=1)\\n    test_x.drop([c],axis=1,inplace=True)\\n    \\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyJP86OsHixz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0e2b1353-356d-4343-846d-78d05b80f474"
      },
      "source": [
        "#Do the training operation from the resepctive features\n",
        "#Linear Regression \n",
        "\n",
        "#Train the model\n",
        "\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "model = linear_model.LinearRegression()\n",
        "model.fit(train_x, train_y)\n",
        "\n",
        "predicted_train_y = model.predict(train_x)\n",
        "#for a,p in zip(train_y,predicted_train_y):\n",
        "#  print(a,\" \",p)\n",
        "predicted_y = model.predict(test_x)\n",
        "print(len(predicted_train_y))\n",
        "\n",
        "print(\"The RMSE Error is \",sqrt(mean_squared_error(predicted_train_y,train_y)))\n",
        "#print(\"Accuracy --> \", model.score(train_x,predicted_train_y)*100)\n",
        "#print(\"Predict value \" + str(model.predict([test_x[142]])))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1460\n",
            "The RMSE Error is  26795.18356335712\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFdt8TpYHmHr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ef3795c-5db4-4d7d-cd27-9e674e74b6fe"
      },
      "source": [
        "#Perform the operation using Random forest\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=1000)\n",
        "model.fit(train_x, train_y)\n",
        "\n",
        "predicted_train_y = model.predict(train_x)\n",
        "#for a,p in zip(train_y,predicted_train_y):\n",
        "#  print(a,\" \",p)\n",
        "predicted_y = model.predict(test_x)\n",
        "print(\"The RMSE Error is \",sqrt(mean_squared_error(predicted_train_y,train_y)))\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The RMSE Error is  11083.808267791283\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WEnygkpHmrD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "782fbcde-5835-4a6f-bcfc-f9448ce21ff2"
      },
      "source": [
        "#Perform gradient boosting \n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "model = GradientBoostingRegressor(n_estimators=1000, max_depth=6)\n",
        "model.fit(train_x, train_y)\n",
        "\n",
        "predicted_train_y = model.predict(train_x)\n",
        "#for a,p in zip(train_y,predicted_train_y):\n",
        "#  print(a,\" \",p)\n",
        "predicted_y = model.predict(test_x)\n",
        "print(\"The RMSE Error is \",sqrt(mean_squared_error(predicted_train_y,train_y)))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The RMSE Error is  48.21217805121048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWW946TjHm1q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "7a6a0d2b-bc97-4c9e-c952-4efb3ec56c60"
      },
      "source": [
        "#parameter optimization\n",
        "\n",
        "print( train_x.columns[train_x.columns.duplicated()])\n",
        "print( test_x.columns[test_x.columns.duplicated()])\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import xgboost\n",
        "\n",
        "classifier=xgboost.XGBRegressor()\n",
        "regressor=xgboost.XGBRegressor()\n",
        "\n",
        "booster=['gbtree','gblinear']\n",
        "base_score=[0.25,0.5,0.75,1]\n",
        "\n",
        "n_estimators = [100, 500, 900, 1100, 1500]\n",
        "max_depth = [2, 3, 5, 10, 15]\n",
        "booster=['gbtree','gblinear']\n",
        "learning_rate=[0.05,0.1,0.15,0.20]\n",
        "min_child_weight=[1,2,3,4]\n",
        "\n",
        "# Define the grid of hyperparameters to search\n",
        "hyperparameter_grid = {\n",
        "    'n_estimators': n_estimators,\n",
        "    'max_depth':max_depth,\n",
        "    'learning_rate':learning_rate,\n",
        "    'min_child_weight':min_child_weight,\n",
        "    'booster':booster,\n",
        "    'base_score':base_score\n",
        "    }\n",
        "# Set up the random search with 4-fold cross validation\n",
        "random_cv = RandomizedSearchCV(estimator=regressor,\n",
        "            param_distributions=hyperparameter_grid,\n",
        "            cv=5, n_iter=50,\n",
        "            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n",
        "            verbose = 5, \n",
        "            return_train_score = True,\n",
        "            random_state=42)\n",
        "random_cv.fit(train_x, train_y)\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index([], dtype='object')\n",
            "Index([], dtype='object')\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:   27.5s\n",
            "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:  4.2min\n",
            "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  8.4min\n",
            "[Parallel(n_jobs=4)]: Done 250 out of 250 | elapsed: 12.9min finished\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  data.base is not None and isinstance(data, np.ndarray) \\\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[09:51:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
              "                   estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
              "                                          colsample_bylevel=1,\n",
              "                                          colsample_bynode=1,\n",
              "                                          colsample_bytree=1, gamma=0,\n",
              "                                          importance_type='gain',\n",
              "                                          learning_rate=0.1, max_delta_step=0,\n",
              "                                          max_depth=3, min_child_weight=1,\n",
              "                                          missing=None, n_estimators=100,\n",
              "                                          n_jobs=1, nthread=None,\n",
              "                                          objective='reg:linear',\n",
              "                                          random_st...\n",
              "                   iid='warn', n_iter=50, n_jobs=4,\n",
              "                   param_distributions={'base_score': [0.25, 0.5, 0.75, 1],\n",
              "                                        'booster': ['gbtree', 'gblinear'],\n",
              "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2],\n",
              "                                        'max_depth': [2, 3, 5, 10, 15],\n",
              "                                        'min_child_weight': [1, 2, 3, 4],\n",
              "                                        'n_estimators': [100, 500, 900, 1100,\n",
              "                                                         1500]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
              "                   return_train_score=True, scoring='neg_mean_absolute_error',\n",
              "                   verbose=5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2FIS711LhPm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f3ec57d3-39ac-40cd-a90f-3bf7629ffd4b"
      },
      "source": [
        "random_cv.best_estimator_"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
              "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
              "             max_depth=2, min_child_weight=1, missing=None, n_estimators=900,\n",
              "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
              "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "             silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4H-ZRSuLnee",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "0708685d-ab5b-48e3-dc5c-b09c5f3bbf7e"
      },
      "source": [
        "\n",
        "model=xgboost.XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
        "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
        "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
        "             max_depth=2, min_child_weight=1, missing=None, n_estimators=900,\n",
        "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
        "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
        "             silent=None, subsample=1, verbosity=1)\n",
        "\n",
        "model.fit(train_x,train_y)\n",
        "predicted_train_y = model.predict(train_x)\n",
        "#for a,p in zip(train_y,predicted_train_y):\n",
        "#  print(a,\" \",p)\n",
        "predicted_y = model.predict(test_x)\n",
        "print(\"The RMSE Error is \",sqrt(mean_squared_error(predicted_train_y,train_y)))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  data.base is not None and isinstance(data, np.ndarray) \\\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[09:57:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "The RMSE Error is  12592.983513566038\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzuaBByUKHIz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0abb9b0e-bdd3-408d-8c65-22d042e75565"
      },
      "source": [
        "#using Neural network to minimize the error\n",
        "# Create the Model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(32, input_dim=train_x.shape[1], activation='relu'))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1))\n",
        "\n",
        "# Compile the Model\n",
        "model.compile(optimizer='adam', loss='mean_squared_logarithmic_error', metrics=[\"mae\"])\n",
        "\n",
        "model.fit(train_x,train_y, epochs=200, batch_size=32)\n",
        "predicted_train_y = model.predict(train_x)\n",
        "#for a,p in zip(train_y,predicted_train_y):\n",
        "#  print(a,\" \",p)\n",
        "predicted_y = model.predict(test_x)\n",
        "print(\"The RMSE Error is \",sqrt(mean_squared_error(predicted_train_y,train_y)))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1702: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/200\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "1168/1168 [==============================] - 1s 712us/step - loss: 144.6871 - mean_absolute_error: 180864.8519 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 2/200\n",
            "1168/1168 [==============================] - 0s 56us/step - loss: 144.6871 - mean_absolute_error: 180864.8523 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 3/200\n",
            "1168/1168 [==============================] - 0s 49us/step - loss: 144.6871 - mean_absolute_error: 180864.8527 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 4/200\n",
            "1168/1168 [==============================] - 0s 52us/step - loss: 144.6871 - mean_absolute_error: 180864.8532 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 5/200\n",
            "1168/1168 [==============================] - 0s 49us/step - loss: 144.6871 - mean_absolute_error: 180864.8547 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 6/200\n",
            "1168/1168 [==============================] - 0s 47us/step - loss: 144.6871 - mean_absolute_error: 180864.8549 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 7/200\n",
            "1168/1168 [==============================] - 0s 47us/step - loss: 144.6871 - mean_absolute_error: 180864.8549 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 8/200\n",
            "1168/1168 [==============================] - 0s 47us/step - loss: 144.6871 - mean_absolute_error: 180864.8530 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 9/200\n",
            "1168/1168 [==============================] - 0s 48us/step - loss: 144.6871 - mean_absolute_error: 180864.8517 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 10/200\n",
            "1168/1168 [==============================] - 0s 48us/step - loss: 144.6871 - mean_absolute_error: 180864.8523 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 11/200\n",
            "1168/1168 [==============================] - 0s 47us/step - loss: 144.6871 - mean_absolute_error: 180864.8525 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 12/200\n",
            "1168/1168 [==============================] - 0s 47us/step - loss: 144.6871 - mean_absolute_error: 180864.8534 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 13/200\n",
            "1168/1168 [==============================] - 0s 47us/step - loss: 144.6871 - mean_absolute_error: 180864.8538 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 14/200\n",
            "1168/1168 [==============================] - 0s 49us/step - loss: 144.6871 - mean_absolute_error: 180864.8547 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 15/200\n",
            "1168/1168 [==============================] - 0s 46us/step - loss: 144.6871 - mean_absolute_error: 180864.8532 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 16/200\n",
            "1168/1168 [==============================] - 0s 46us/step - loss: 144.6871 - mean_absolute_error: 180864.8519 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 17/200\n",
            "1168/1168 [==============================] - 0s 46us/step - loss: 144.6871 - mean_absolute_error: 180864.8540 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 18/200\n",
            "1168/1168 [==============================] - 0s 45us/step - loss: 144.6871 - mean_absolute_error: 180864.8525 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 19/200\n",
            "1168/1168 [==============================] - 0s 54us/step - loss: 144.6871 - mean_absolute_error: 180864.8527 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 20/200\n",
            "1168/1168 [==============================] - 0s 51us/step - loss: 144.6871 - mean_absolute_error: 180864.8551 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 21/200\n",
            "1168/1168 [==============================] - 0s 50us/step - loss: 144.6871 - mean_absolute_error: 180864.8532 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 22/200\n",
            "1168/1168 [==============================] - 0s 51us/step - loss: 144.6871 - mean_absolute_error: 180864.8530 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 23/200\n",
            "1168/1168 [==============================] - 0s 51us/step - loss: 144.6871 - mean_absolute_error: 180864.8553 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 24/200\n",
            "1168/1168 [==============================] - 0s 54us/step - loss: 144.6871 - mean_absolute_error: 180864.8536 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 25/200\n",
            "1168/1168 [==============================] - 0s 47us/step - loss: 144.6871 - mean_absolute_error: 180864.8538 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 26/200\n",
            "1168/1168 [==============================] - 0s 50us/step - loss: 144.6871 - mean_absolute_error: 180864.8532 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 27/200\n",
            "1168/1168 [==============================] - 0s 65us/step - loss: 144.6871 - mean_absolute_error: 180864.8510 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 28/200\n",
            "1168/1168 [==============================] - 0s 52us/step - loss: 144.6871 - mean_absolute_error: 180864.8527 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 29/200\n",
            "1168/1168 [==============================] - 0s 59us/step - loss: 144.6871 - mean_absolute_error: 180864.8519 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 30/200\n",
            "1168/1168 [==============================] - 0s 50us/step - loss: 144.6871 - mean_absolute_error: 180864.8540 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 31/200\n",
            "1168/1168 [==============================] - 0s 54us/step - loss: 144.6871 - mean_absolute_error: 180864.8549 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 32/200\n",
            "1168/1168 [==============================] - 0s 47us/step - loss: 144.6871 - mean_absolute_error: 180864.8532 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 33/200\n",
            "1168/1168 [==============================] - 0s 48us/step - loss: 144.6871 - mean_absolute_error: 180864.8545 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 34/200\n",
            "1168/1168 [==============================] - 0s 48us/step - loss: 144.6871 - mean_absolute_error: 180864.8553 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 35/200\n",
            "1168/1168 [==============================] - 0s 45us/step - loss: 144.6871 - mean_absolute_error: 180864.8540 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 36/200\n",
            "1168/1168 [==============================] - 0s 47us/step - loss: 144.6871 - mean_absolute_error: 180864.8542 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 37/200\n",
            "1168/1168 [==============================] - 0s 51us/step - loss: 144.6871 - mean_absolute_error: 180864.8540 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 38/200\n",
            "1168/1168 [==============================] - 0s 49us/step - loss: 144.6871 - mean_absolute_error: 180864.8523 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 39/200\n",
            "1168/1168 [==============================] - 0s 57us/step - loss: 144.6871 - mean_absolute_error: 180864.8549 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 40/200\n",
            "1168/1168 [==============================] - 0s 58us/step - loss: 144.6871 - mean_absolute_error: 180864.8527 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 41/200\n",
            "1168/1168 [==============================] - 0s 51us/step - loss: 144.6871 - mean_absolute_error: 180864.8527 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 42/200\n",
            "1168/1168 [==============================] - 0s 53us/step - loss: 144.6871 - mean_absolute_error: 180864.8532 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 43/200\n",
            "1168/1168 [==============================] - 0s 51us/step - loss: 144.6871 - mean_absolute_error: 180864.8527 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 44/200\n",
            "1168/1168 [==============================] - 0s 50us/step - loss: 144.6871 - mean_absolute_error: 180864.8545 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 45/200\n",
            "1168/1168 [==============================] - 0s 50us/step - loss: 144.6871 - mean_absolute_error: 180864.8527 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 46/200\n",
            "1168/1168 [==============================] - 0s 49us/step - loss: 144.6871 - mean_absolute_error: 180864.8519 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 47/200\n",
            "1168/1168 [==============================] - 0s 49us/step - loss: 144.6871 - mean_absolute_error: 180864.8536 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 48/200\n",
            "1168/1168 [==============================] - 0s 50us/step - loss: 144.6871 - mean_absolute_error: 180864.8553 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 49/200\n",
            "1168/1168 [==============================] - 0s 66us/step - loss: 144.6871 - mean_absolute_error: 180864.8527 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 50/200\n",
            "1168/1168 [==============================] - 0s 58us/step - loss: 144.6871 - mean_absolute_error: 180864.8527 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 51/200\n",
            "1168/1168 [==============================] - 0s 50us/step - loss: 144.6871 - mean_absolute_error: 180864.8545 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 52/200\n",
            "1168/1168 [==============================] - 0s 54us/step - loss: 144.6871 - mean_absolute_error: 180864.8538 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 53/200\n",
            "1168/1168 [==============================] - 0s 52us/step - loss: 144.6871 - mean_absolute_error: 180864.8538 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 54/200\n",
            "1168/1168 [==============================] - 0s 48us/step - loss: 144.6871 - mean_absolute_error: 180864.8515 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 55/200\n",
            "1168/1168 [==============================] - 0s 46us/step - loss: 144.6871 - mean_absolute_error: 180864.8553 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 56/200\n",
            "1168/1168 [==============================] - 0s 47us/step - loss: 144.6871 - mean_absolute_error: 180864.8530 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 57/200\n",
            "1168/1168 [==============================] - 0s 46us/step - loss: 144.6871 - mean_absolute_error: 180864.8536 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 58/200\n",
            "1168/1168 [==============================] - 0s 48us/step - loss: 144.6871 - mean_absolute_error: 180864.8547 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 59/200\n",
            "1168/1168 [==============================] - 0s 46us/step - loss: 144.6871 - mean_absolute_error: 180864.8527 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 60/200\n",
            "1168/1168 [==============================] - 0s 49us/step - loss: 144.6871 - mean_absolute_error: 180864.8557 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 61/200\n",
            "1168/1168 [==============================] - 0s 46us/step - loss: 144.6871 - mean_absolute_error: 180864.8545 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 62/200\n",
            "1168/1168 [==============================] - 0s 48us/step - loss: 144.6871 - mean_absolute_error: 180864.8512 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 63/200\n",
            "1168/1168 [==============================] - 0s 46us/step - loss: 144.6871 - mean_absolute_error: 180864.8536 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 64/200\n",
            "1168/1168 [==============================] - 0s 47us/step - loss: 144.6871 - mean_absolute_error: 180864.8523 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 65/200\n",
            "1168/1168 [==============================] - 0s 47us/step - loss: 144.6871 - mean_absolute_error: 180864.8538 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 66/200\n",
            "1168/1168 [==============================] - 0s 48us/step - loss: 144.6871 - mean_absolute_error: 180864.8540 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 67/200\n",
            "1168/1168 [==============================] - 0s 47us/step - loss: 144.6871 - mean_absolute_error: 180864.8527 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 68/200\n",
            "1168/1168 [==============================] - 0s 46us/step - loss: 144.6871 - mean_absolute_error: 180864.8545 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 69/200\n",
            "1168/1168 [==============================] - 0s 46us/step - loss: 144.6871 - mean_absolute_error: 180864.8540 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 70/200\n",
            "1168/1168 [==============================] - 0s 57us/step - loss: 144.6871 - mean_absolute_error: 180864.8538 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 71/200\n",
            "1168/1168 [==============================] - 0s 59us/step - loss: 144.6871 - mean_absolute_error: 180864.8536 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 72/200\n",
            "1168/1168 [==============================] - 0s 48us/step - loss: 144.6871 - mean_absolute_error: 180864.8525 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 73/200\n",
            "1168/1168 [==============================] - 0s 56us/step - loss: 144.6871 - mean_absolute_error: 180864.8549 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 74/200\n",
            "1168/1168 [==============================] - 0s 49us/step - loss: 144.6871 - mean_absolute_error: 180864.8525 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 75/200\n",
            "1168/1168 [==============================] - 0s 51us/step - loss: 144.6871 - mean_absolute_error: 180864.8536 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 76/200\n",
            "1168/1168 [==============================] - 0s 51us/step - loss: 144.6871 - mean_absolute_error: 180864.8534 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 77/200\n",
            "1168/1168 [==============================] - 0s 51us/step - loss: 144.6871 - mean_absolute_error: 180864.8527 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 78/200\n",
            "1168/1168 [==============================] - 0s 55us/step - loss: 144.6871 - mean_absolute_error: 180864.8527 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 79/200\n",
            "1168/1168 [==============================] - 0s 54us/step - loss: 144.6871 - mean_absolute_error: 180864.8545 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 80/200\n",
            "1168/1168 [==============================] - 0s 49us/step - loss: 144.6871 - mean_absolute_error: 180864.8530 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 81/200\n",
            "1168/1168 [==============================] - 0s 52us/step - loss: 144.6871 - mean_absolute_error: 180864.8538 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 82/200\n",
            "1168/1168 [==============================] - 0s 49us/step - loss: 144.6871 - mean_absolute_error: 180864.8547 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 83/200\n",
            "1168/1168 [==============================] - 0s 50us/step - loss: 144.6871 - mean_absolute_error: 180864.8517 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 84/200\n",
            "1168/1168 [==============================] - 0s 49us/step - loss: 144.6871 - mean_absolute_error: 180864.8519 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 85/200\n",
            "1168/1168 [==============================] - 0s 49us/step - loss: 144.6871 - mean_absolute_error: 180864.8523 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 86/200\n",
            "1168/1168 [==============================] - 0s 60us/step - loss: 144.6871 - mean_absolute_error: 180864.8540 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 87/200\n",
            "1168/1168 [==============================] - 0s 59us/step - loss: 144.6871 - mean_absolute_error: 180864.8532 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 88/200\n",
            "1168/1168 [==============================] - 0s 61us/step - loss: 144.6871 - mean_absolute_error: 180864.8532 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 89/200\n",
            "1168/1168 [==============================] - 0s 48us/step - loss: 144.6871 - mean_absolute_error: 180864.8527 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 90/200\n",
            "1168/1168 [==============================] - 0s 52us/step - loss: 144.6871 - mean_absolute_error: 180864.8540 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 91/200\n",
            "1168/1168 [==============================] - 0s 63us/step - loss: 144.6871 - mean_absolute_error: 180864.8545 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 92/200\n",
            "1168/1168 [==============================] - 0s 59us/step - loss: 144.6871 - mean_absolute_error: 180864.8521 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 93/200\n",
            "1168/1168 [==============================] - 0s 50us/step - loss: 144.6871 - mean_absolute_error: 180864.8538 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 94/200\n",
            "1168/1168 [==============================] - 0s 58us/step - loss: 144.6871 - mean_absolute_error: 180864.8545 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 95/200\n",
            "1168/1168 [==============================] - 0s 51us/step - loss: 144.6871 - mean_absolute_error: 180864.8536 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 96/200\n",
            "1168/1168 [==============================] - 0s 51us/step - loss: 144.6871 - mean_absolute_error: 180864.8536 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 97/200\n",
            "1168/1168 [==============================] - 0s 48us/step - loss: 144.6871 - mean_absolute_error: 180864.8536 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 98/200\n",
            "1168/1168 [==============================] - 0s 48us/step - loss: 144.6871 - mean_absolute_error: 180864.8545 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 99/200\n",
            "1168/1168 [==============================] - 0s 49us/step - loss: 144.6871 - mean_absolute_error: 180864.8527 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 100/200\n",
            "1168/1168 [==============================] - 0s 48us/step - loss: 144.6871 - mean_absolute_error: 180864.8530 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 101/200\n",
            "1168/1168 [==============================] - 0s 55us/step - loss: 144.6871 - mean_absolute_error: 180864.8540 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 102/200\n",
            "1168/1168 [==============================] - 0s 52us/step - loss: 144.6871 - mean_absolute_error: 180864.8553 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 103/200\n",
            "1168/1168 [==============================] - 0s 59us/step - loss: 144.6871 - mean_absolute_error: 180864.8527 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 104/200\n",
            "1168/1168 [==============================] - 0s 62us/step - loss: 144.6871 - mean_absolute_error: 180864.8542 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 105/200\n",
            "1168/1168 [==============================] - 0s 64us/step - loss: 144.6871 - mean_absolute_error: 180864.8540 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 106/200\n",
            "1168/1168 [==============================] - 0s 51us/step - loss: 144.6871 - mean_absolute_error: 180864.8549 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 107/200\n",
            "1168/1168 [==============================] - 0s 48us/step - loss: 144.6871 - mean_absolute_error: 180864.8527 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 108/200\n",
            "1168/1168 [==============================] - 0s 50us/step - loss: 144.6871 - mean_absolute_error: 180864.8534 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 109/200\n",
            "1168/1168 [==============================] - 0s 49us/step - loss: 144.6871 - mean_absolute_error: 180864.8532 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 110/200\n",
            "1168/1168 [==============================] - 0s 51us/step - loss: 144.6871 - mean_absolute_error: 180864.8536 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 111/200\n",
            "1168/1168 [==============================] - 0s 51us/step - loss: 144.6871 - mean_absolute_error: 180864.8527 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 112/200\n",
            "1168/1168 [==============================] - 0s 49us/step - loss: 144.6871 - mean_absolute_error: 180864.8519 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 113/200\n",
            "1168/1168 [==============================] - 0s 49us/step - loss: 144.6871 - mean_absolute_error: 180864.8527 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 114/200\n",
            "1168/1168 [==============================] - 0s 50us/step - loss: 144.6871 - mean_absolute_error: 180864.8534 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 115/200\n",
            "1168/1168 [==============================] - 0s 52us/step - loss: 144.6871 - mean_absolute_error: 180864.8551 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 116/200\n",
            "1168/1168 [==============================] - 0s 49us/step - loss: 144.6871 - mean_absolute_error: 180864.8551 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 117/200\n",
            "1168/1168 [==============================] - 0s 61us/step - loss: 144.6871 - mean_absolute_error: 180864.8536 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 118/200\n",
            "1168/1168 [==============================] - 0s 47us/step - loss: 144.6871 - mean_absolute_error: 180864.8530 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 119/200\n",
            "1168/1168 [==============================] - 0s 49us/step - loss: 144.6871 - mean_absolute_error: 180864.8545 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 120/200\n",
            "1168/1168 [==============================] - 0s 46us/step - loss: 144.6871 - mean_absolute_error: 180864.8562 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 121/200\n",
            "1168/1168 [==============================] - 0s 50us/step - loss: 144.6871 - mean_absolute_error: 180864.8530 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 122/200\n",
            "1168/1168 [==============================] - 0s 50us/step - loss: 144.6871 - mean_absolute_error: 180864.8540 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 123/200\n",
            "1168/1168 [==============================] - 0s 50us/step - loss: 144.6871 - mean_absolute_error: 180864.8557 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 124/200\n",
            "1168/1168 [==============================] - 0s 47us/step - loss: 144.6871 - mean_absolute_error: 180864.8540 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 125/200\n",
            "1168/1168 [==============================] - 0s 49us/step - loss: 144.6871 - mean_absolute_error: 180864.8540 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 126/200\n",
            "1168/1168 [==============================] - 0s 45us/step - loss: 144.6871 - mean_absolute_error: 180864.8532 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 127/200\n",
            "1168/1168 [==============================] - 0s 48us/step - loss: 144.6871 - mean_absolute_error: 180864.8536 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 128/200\n",
            "1168/1168 [==============================] - 0s 46us/step - loss: 144.6871 - mean_absolute_error: 180864.8545 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 129/200\n",
            "1168/1168 [==============================] - 0s 51us/step - loss: 144.6871 - mean_absolute_error: 180864.8523 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 130/200\n",
            "1168/1168 [==============================] - 0s 47us/step - loss: 144.6871 - mean_absolute_error: 180864.8532 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 131/200\n",
            "1168/1168 [==============================] - 0s 48us/step - loss: 144.6871 - mean_absolute_error: 180864.8536 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 132/200\n",
            "1168/1168 [==============================] - 0s 46us/step - loss: 144.6871 - mean_absolute_error: 180864.8545 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 133/200\n",
            "1168/1168 [==============================] - 0s 45us/step - loss: 144.6871 - mean_absolute_error: 180864.8553 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 134/200\n",
            "1168/1168 [==============================] - 0s 47us/step - loss: 144.6871 - mean_absolute_error: 180864.8532 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 135/200\n",
            "1168/1168 [==============================] - 0s 44us/step - loss: 144.6871 - mean_absolute_error: 180864.8525 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 136/200\n",
            "1168/1168 [==============================] - 0s 48us/step - loss: 144.6871 - mean_absolute_error: 180864.8536 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 137/200\n",
            "1168/1168 [==============================] - 0s 47us/step - loss: 144.6871 - mean_absolute_error: 180864.8540 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 138/200\n",
            "1168/1168 [==============================] - 0s 45us/step - loss: 144.6871 - mean_absolute_error: 180864.8545 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 139/200\n",
            "1168/1168 [==============================] - 0s 54us/step - loss: 144.6871 - mean_absolute_error: 180864.8538 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 140/200\n",
            "1168/1168 [==============================] - 0s 48us/step - loss: 144.6871 - mean_absolute_error: 180864.8532 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 141/200\n",
            "1168/1168 [==============================] - 0s 53us/step - loss: 144.6871 - mean_absolute_error: 180864.8536 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 142/200\n",
            "1168/1168 [==============================] - 0s 44us/step - loss: 144.6871 - mean_absolute_error: 180864.8527 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 143/200\n",
            "1168/1168 [==============================] - 0s 47us/step - loss: 144.6871 - mean_absolute_error: 180864.8540 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 144/200\n",
            "1168/1168 [==============================] - 0s 45us/step - loss: 144.6871 - mean_absolute_error: 180864.8545 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 145/200\n",
            "1168/1168 [==============================] - 0s 45us/step - loss: 144.6871 - mean_absolute_error: 180864.8527 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 146/200\n",
            "1168/1168 [==============================] - 0s 46us/step - loss: 144.6871 - mean_absolute_error: 180864.8562 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 147/200\n",
            "1168/1168 [==============================] - 0s 45us/step - loss: 144.6871 - mean_absolute_error: 180864.8547 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 148/200\n",
            "1168/1168 [==============================] - 0s 49us/step - loss: 144.6871 - mean_absolute_error: 180864.8534 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 149/200\n",
            "1168/1168 [==============================] - 0s 48us/step - loss: 144.6871 - mean_absolute_error: 180864.8540 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 150/200\n",
            "1168/1168 [==============================] - 0s 49us/step - loss: 144.6871 - mean_absolute_error: 180864.8562 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 151/200\n",
            "1168/1168 [==============================] - 0s 50us/step - loss: 144.6871 - mean_absolute_error: 180864.8562 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 152/200\n",
            "1168/1168 [==============================] - 0s 46us/step - loss: 144.6871 - mean_absolute_error: 180864.8532 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 153/200\n",
            "1168/1168 [==============================] - 0s 45us/step - loss: 144.6871 - mean_absolute_error: 180864.8525 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 154/200\n",
            "1168/1168 [==============================] - 0s 45us/step - loss: 144.6871 - mean_absolute_error: 180864.8527 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 155/200\n",
            "1168/1168 [==============================] - 0s 45us/step - loss: 144.6871 - mean_absolute_error: 180864.8534 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 156/200\n",
            "1168/1168 [==============================] - 0s 44us/step - loss: 144.6871 - mean_absolute_error: 180864.8545 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 157/200\n",
            "1168/1168 [==============================] - 0s 46us/step - loss: 144.6871 - mean_absolute_error: 180864.8532 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 158/200\n",
            "1168/1168 [==============================] - 0s 47us/step - loss: 144.6871 - mean_absolute_error: 180864.8540 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 159/200\n",
            "1168/1168 [==============================] - 0s 47us/step - loss: 144.6871 - mean_absolute_error: 180864.8519 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 160/200\n",
            "1168/1168 [==============================] - 0s 48us/step - loss: 144.6871 - mean_absolute_error: 180864.8542 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 161/200\n",
            "1168/1168 [==============================] - 0s 48us/step - loss: 144.6871 - mean_absolute_error: 180864.8536 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 162/200\n",
            "1168/1168 [==============================] - 0s 48us/step - loss: 144.6871 - mean_absolute_error: 180864.8542 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 163/200\n",
            "1168/1168 [==============================] - 0s 49us/step - loss: 144.6871 - mean_absolute_error: 180864.8527 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 164/200\n",
            "1168/1168 [==============================] - 0s 46us/step - loss: 144.6871 - mean_absolute_error: 180864.8540 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 165/200\n",
            "1168/1168 [==============================] - 0s 46us/step - loss: 144.6871 - mean_absolute_error: 180864.8540 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 166/200\n",
            "1168/1168 [==============================] - 0s 46us/step - loss: 144.6871 - mean_absolute_error: 180864.8525 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 167/200\n",
            "1168/1168 [==============================] - 0s 46us/step - loss: 144.6871 - mean_absolute_error: 180864.8553 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 168/200\n",
            "1168/1168 [==============================] - 0s 45us/step - loss: 144.6871 - mean_absolute_error: 180864.8532 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 169/200\n",
            "1168/1168 [==============================] - 0s 49us/step - loss: 144.6871 - mean_absolute_error: 180864.8557 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 170/200\n",
            "1168/1168 [==============================] - 0s 50us/step - loss: 144.6871 - mean_absolute_error: 180864.8553 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 171/200\n",
            "1168/1168 [==============================] - 0s 52us/step - loss: 144.6871 - mean_absolute_error: 180864.8549 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 172/200\n",
            "1168/1168 [==============================] - 0s 59us/step - loss: 144.6871 - mean_absolute_error: 180864.8534 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 173/200\n",
            "1168/1168 [==============================] - 0s 58us/step - loss: 144.6871 - mean_absolute_error: 180864.8540 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 174/200\n",
            "1168/1168 [==============================] - 0s 62us/step - loss: 144.6871 - mean_absolute_error: 180864.8549 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 175/200\n",
            "1168/1168 [==============================] - 0s 47us/step - loss: 144.6871 - mean_absolute_error: 180864.8536 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 176/200\n",
            "1168/1168 [==============================] - 0s 49us/step - loss: 144.6871 - mean_absolute_error: 180864.8523 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 177/200\n",
            "1168/1168 [==============================] - 0s 57us/step - loss: 144.6871 - mean_absolute_error: 180864.8534 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 178/200\n",
            "1168/1168 [==============================] - 0s 50us/step - loss: 144.6871 - mean_absolute_error: 180864.8538 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 179/200\n",
            "1168/1168 [==============================] - 0s 49us/step - loss: 144.6871 - mean_absolute_error: 180864.8572 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 180/200\n",
            "1168/1168 [==============================] - 0s 51us/step - loss: 144.6871 - mean_absolute_error: 180864.8553 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 181/200\n",
            "1168/1168 [==============================] - 0s 48us/step - loss: 144.6871 - mean_absolute_error: 180864.8545 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 182/200\n",
            "1168/1168 [==============================] - 0s 48us/step - loss: 144.6871 - mean_absolute_error: 180864.8553 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 183/200\n",
            "1168/1168 [==============================] - 0s 61us/step - loss: 144.6871 - mean_absolute_error: 180864.8536 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 184/200\n",
            "1168/1168 [==============================] - 0s 50us/step - loss: 144.6871 - mean_absolute_error: 180864.8540 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 185/200\n",
            "1168/1168 [==============================] - 0s 50us/step - loss: 144.6871 - mean_absolute_error: 180864.8527 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 186/200\n",
            "1168/1168 [==============================] - 0s 45us/step - loss: 144.6871 - mean_absolute_error: 180864.8536 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 187/200\n",
            "1168/1168 [==============================] - 0s 47us/step - loss: 144.6871 - mean_absolute_error: 180864.8545 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 188/200\n",
            "1168/1168 [==============================] - 0s 46us/step - loss: 144.6871 - mean_absolute_error: 180864.8553 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 189/200\n",
            "1168/1168 [==============================] - 0s 48us/step - loss: 144.6871 - mean_absolute_error: 180864.8545 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 190/200\n",
            "1168/1168 [==============================] - 0s 47us/step - loss: 144.6871 - mean_absolute_error: 180864.8542 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 191/200\n",
            "1168/1168 [==============================] - 0s 44us/step - loss: 144.6871 - mean_absolute_error: 180864.8545 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 192/200\n",
            "1168/1168 [==============================] - 0s 50us/step - loss: 144.6871 - mean_absolute_error: 180864.8532 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 193/200\n",
            "1168/1168 [==============================] - 0s 48us/step - loss: 144.6871 - mean_absolute_error: 180864.8527 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 194/200\n",
            "1168/1168 [==============================] - 0s 48us/step - loss: 144.6871 - mean_absolute_error: 180864.8519 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 195/200\n",
            "1168/1168 [==============================] - 0s 51us/step - loss: 144.6871 - mean_absolute_error: 180864.8545 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 196/200\n",
            "1168/1168 [==============================] - 0s 48us/step - loss: 144.6871 - mean_absolute_error: 180864.8545 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 197/200\n",
            "1168/1168 [==============================] - 0s 46us/step - loss: 144.6871 - mean_absolute_error: 180864.8549 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 198/200\n",
            "1168/1168 [==============================] - 0s 47us/step - loss: 144.6871 - mean_absolute_error: 180864.8542 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 199/200\n",
            "1168/1168 [==============================] - 0s 49us/step - loss: 144.6871 - mean_absolute_error: 180864.8547 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "Epoch 200/200\n",
            "1168/1168 [==============================] - 0s 48us/step - loss: 144.6871 - mean_absolute_error: 180864.8521 - val_loss: 144.9388 - val_mean_absolute_error: 182514.2517\n",
            "The RMSE Error is  197871.9222149798\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}